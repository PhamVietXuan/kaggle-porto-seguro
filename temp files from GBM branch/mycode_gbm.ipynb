{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse as ssp\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgbm\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (7,7)\n",
    "plt.rcParams[\"font.size\"] = 14\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./data/\"\n",
    "\n",
    "train = pd.read_csv(path+'train.csv')\n",
    "train_label = train['target']\n",
    "train_id = train['id']\n",
    "test = pd.read_csv(path+'test.csv')\n",
    "test_id = test['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = train.drop([\"id\", \"target\"], axis=1).columns.tolist()\n",
    "# Các cột categorical\n",
    "cat_features = [c for c in feature_names if ('cat' in c)]\n",
    "# Các cột internal + binary\n",
    "num_features = [c for c in feature_names if ('cat' not in c and 'calc' not in c)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['missing'] = (train==-1).sum(axis=1).astype(float)\n",
    "test['missing'] = (test==-1).sum(axis=1).astype(float)\n",
    "num_features.append('missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cat_features:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train[c])\n",
    "    train[c] = le.transform(train[c])\n",
    "    test[c] = le.transform(test[c])\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(train[cat_features])\n",
    "X_cat = enc.transform(train[cat_features])\n",
    "X_t_cat = enc.transform(test[cat_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_features = [c for c in feature_names if 'ind' in c]\n",
    "count=0\n",
    "for c in ind_features:\n",
    "    if count==0:\n",
    "        train['new_ind'] = train[c].astype(str)+'_'\n",
    "        test['new_ind'] = test[c].astype(str)+'_'\n",
    "        count+=1\n",
    "    else:\n",
    "        train['new_ind'] += train[c].astype(str)+'_'\n",
    "        test['new_ind'] += test[c].astype(str)+'_'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_count_features = []\n",
    "for c in cat_features+['new_ind']:\n",
    "    d = pd.concat([train[c],test[c]]).value_counts().to_dict()\n",
    "    train['%s_count'%c] = train[c].apply(lambda x:d.get(x,0))\n",
    "    test['%s_count'%c] = test[c].apply(lambda x:d.get(x,0))\n",
    "    cat_count_features.append('%s_count'%c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = [train[num_features+cat_count_features].values, X_cat]\n",
    "test_list = [test[num_features+cat_count_features].values, X_t_cat]\n",
    "\n",
    "# Nén dữ liệu: Compressed Sparse Row format\n",
    "X = ssp.hstack(train_list).tocsr()\n",
    "X_test = ssp.hstack(test_list).tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gini(y_true, y_pred):\n",
    "    # check and get number of samples\n",
    "    assert y_true.shape == y_pred.shape\n",
    "    n_samples = y_true.shape[0]\n",
    "\n",
    "    # sort rows on prediction column\n",
    "    # (from largest to smallest)\n",
    "    arr = np.array([y_true, y_pred]).transpose()\n",
    "    true_order = arr[arr[:, 0].argsort()][::-1, 0]\n",
    "    pred_order = arr[arr[:, 1].argsort()][::-1, 0]\n",
    "\n",
    "    # get Lorenz curves\n",
    "    L_true = np.cumsum(true_order) * 1. / np.sum(true_order)\n",
    "    L_pred = np.cumsum(pred_order) * 1. / np.sum(pred_order)\n",
    "    L_ones = np.linspace(1 / n_samples, 1, n_samples)\n",
    "\n",
    "    # get Gini coefficients (area between curves)\n",
    "    G_true = np.sum(L_ones - L_true)\n",
    "    G_pred = np.sum(L_ones - L_pred)\n",
    "\n",
    "    # normalize to true Gini coefficient\n",
    "    return G_pred * 1. / G_true\n",
    "\n",
    "def evalerror(preds, dtrain):\n",
    "    labels = dtrain.get_label()\n",
    "    return 'gini', Gini(labels, preds), True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NFOLDS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X, y, X_test, y_test):\n",
    "    param_grid = {\n",
    "        'objective': 'binary',\n",
    "        'verbosity': 0,\n",
    "        'num_boost_round': 10000,\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 5, 55, step=5),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 0, 150, step=10),\n",
    "        \"min_child_weight\": trial.suggest_float(\"min_child_weight\", 0.0, 200.0),\n",
    "        \"feature_fraction\": trial.suggest_float(\"feature_fraction\", 0.2, 0.9, step=0.1),\n",
    "        \"seed\": 12, # Thay thế seed\n",
    "    }\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=218)\n",
    "\n",
    "    cv_train = np.zeros(len(y))\n",
    "    cv_pred = np.zeros(len(y_test))\n",
    "\n",
    "    kf = kfold.split(X, y)\n",
    "\n",
    "    best_trees = []\n",
    "    fold_scores = []\n",
    "\n",
    "    for i, (train_fold, validate) in enumerate(kf):\n",
    "        X_train, X_validate, label_train, label_validate = X[train_fold, :], X[validate, :], y[train_fold], y[validate]\n",
    "\n",
    "        dtrain = lgbm.Dataset(X_train, label_train)\n",
    "        dvalid = lgbm.Dataset(X_validate, label_validate, reference=dtrain)\n",
    "\n",
    "        bst = lgbm.train(param_grid, dtrain, valid_sets=dvalid, feval=evalerror, verbose_eval=100,\n",
    "                         early_stopping_rounds=100,\n",
    "                         callbacks=[LightGBMPruningCallback(trial, \"gini\")])\n",
    "\n",
    "        best_trees.append(bst.best_iteration)\n",
    "        cv_pred += bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "        cv_train[validate] += bst.predict(X_validate)\n",
    "\n",
    "        score = Gini(label_validate, cv_train[validate])\n",
    "        print(score)\n",
    "        fold_scores.append(score)\n",
    "\n",
    "    cv_pred /= NFOLDS\n",
    "\n",
    "    cv_score = Gini(y, cv_train)\n",
    "    print(\"cv score: {cv_score}\")\n",
    "    print(fold_scores)\n",
    "    test_score = Gini(y_test, cv_pred)\n",
    "    print(\"test score: {test_score}\")\n",
    "    print(best_trees, np.mean(best_trees))\n",
    "\n",
    "    return test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_gbm(params):\n",
    "    cv_train = np.zeros(len(train_label))\n",
    "    cv_pred = np.zeros(len(test_id))\n",
    "\n",
    "    kfold = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=218)\n",
    "    kf = kfold.split(X, train_label)\n",
    "\n",
    "    #best_trees = []\n",
    "    fold_scores = []\n",
    "\n",
    "    for i, (train_fold, validate) in enumerate(kf):\n",
    "        print(\"Fold {}/{}\".format(i+1, NFOLDS))\n",
    "\n",
    "        X_train, X_validate, label_train, label_validate = \\\n",
    "            X[train_fold, :], X[validate, :], train_label[train_fold], train_label[validate]\n",
    "\n",
    "        dtrain = lgbm.Dataset(X_train, label_train)\n",
    "        dvalid = lgbm.Dataset(X_validate, label_validate, reference=dtrain)\n",
    "        \n",
    "        bst = lgbm.train(params, dtrain, valid_sets=dvalid, feval=evalerror, verbose_eval=100,\n",
    "                        early_stopping_rounds=100)\n",
    "\n",
    "        #best_trees.append(bst.best_iteration)\n",
    "        cv_pred += bst.predict(X_test, num_iteration=bst.best_iteration)\n",
    "        cv_train[validate] += bst.predict(X_validate, num_iteration=bst.best_iteration)\n",
    "\n",
    "        score = Gini(label_validate, cv_train[validate])\n",
    "        print(score)\n",
    "        fold_scores.append(score)\n",
    "\n",
    "    cv_pred /= NFOLDS\n",
    "\n",
    "    print(fold_scores)\n",
    "\n",
    "    return cv_train, cv_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FIXED_PARAMS = {'objective': 'binary', 'verbosity': 0, 'num_boost_round': 10000}\n",
    "\n",
    "SEARCH_PARAMS =     [{'num_leaves': 15,\n",
    "                    'feature_fraction': 0.5,\n",
    "                    'min_child_samples': 100,\n",
    "                    'min_child_weight': 101.94095152382667,\n",
    "                    'seed': 0},\n",
    "                    {'num_leaves': 15,\n",
    "                    'feature_fraction': 0.5,\n",
    "                    'min_child_samples': 60,\n",
    "                    'min_child_weight': 124.66803210058042,\n",
    "                    'seed': 2},\n",
    "                    {'num_leaves': 15,\n",
    "                    'feature_fraction': 0.5,\n",
    "                    'min_child_samples': 150,\n",
    "                    'min_child_weight': 148.13731979766956,\n",
    "                    'seed': 5},\n",
    "                    {'num_leaves': 15,\n",
    "                    'feature_fraction': 0.5,\n",
    "                    'min_child_samples': 30,\n",
    "                    'min_child_weight': 157.2373873709297,\n",
    "                    'seed': 7},\n",
    "                    {'num_leaves': 15,\n",
    "                    'feature_fraction': 0.5,\n",
    "                    'min_child_samples': 10,\n",
    "                    'min_child_weight': 125.16184758062035,\n",
    "                    'seed': 12}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_seed = len(SEARCH_PARAMS)\n",
    "x_score = []\n",
    "final_cv_train = np.zeros(len(train_label))\n",
    "final_cv_pred = np.zeros(len(test_id))\n",
    "for s, s_param in enumerate(SEARCH_PARAMS):\n",
    "    print(\"param\", s)\n",
    "    params = {**s_param, **FIXED_PARAMS}\n",
    "\n",
    "    cv_train, cv_pred = cv_gbm(params)\n",
    "    final_cv_train += cv_train\n",
    "    final_cv_pred += cv_pred\n",
    "\n",
    "    cv_score = Gini(train_label, cv_train)\n",
    "    print(\"cv score:\", cv_score)\n",
    "    print(\"current score:\", Gini(train_label, final_cv_train / (s + 1.)))\n",
    "\n",
    "    x_score.append(cv_score)\n",
    "\n",
    "print(\"cv scores:\", x_score)\n",
    "pd.DataFrame({'id': test_id, 'target': final_cv_pred / num_seed}).to_csv('./lgbm3_pred_avg.csv', index=False)\n",
    "#pd.DataFrame({'id': train_id, 'target': final_cv_train / num_seed}).to_csv('./lgbm3_cv_avg.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
